import openai
import json
import os
from pathlib import Path
from typing import Dict, List, Any, Optional
from .utils import DatabaseManager
from .config import AgentConfig
from dotenv import load_dotenv
load_dotenv()

class OpenAINovelAnalysisAgent:
    """
    OpenAI APIë¥¼ í™œìš©í•œ ì†Œì„¤ íŒŒì¼ ë¶„ì„ ì—ì´ì „íŠ¸
    """
    
    def __init__(self, api_key: str = None, database_path: str = "Database"):
        self.database_path = Path(database_path)
        self.db_manager = DatabaseManager(database_path)
        self.config = AgentConfig()
        
        # OpenAI API í‚¤ ì„¤ì •
        if api_key:
            self.client = openai.OpenAI(api_key=api_key)
        elif os.getenv("OPENAI_API_KEY"):
            self.client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        else:
            raise ValueError("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ api_key ë§¤ê°œë³€ìˆ˜ë¥¼ ì „ë‹¬í•˜ì„¸ìš”.")
    
    def analyze_new_file(self, novel_name: str, file_name: str, file_content: str, progress_callback=None) -> Dict[str, Any]:
        """
        OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œ ì¶”ê°€ëœ íŒŒì¼ì„ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜
        
        Args:
            novel_name: ì†Œì„¤ ì´ë¦„
            file_name: íŒŒì¼ ì´ë¦„
            file_content: íŒŒì¼ ë‚´ìš©
            progress_callback: ì§„í–‰ ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•  ì½œë°± í•¨ìˆ˜ (ì„ íƒ)
        
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            if progress_callback:
                progress_callback(f"ğŸ” ë¶„ì„ ì‹œì‘: {file_name}")
            print(f"ğŸ” ë¶„ì„ ì‹œì‘: {file_name}")
            
            # 1. ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ìˆ˜ì§‘
            existing_data = self._collect_existing_data(novel_name)
            msg = f"ğŸ“Š ê¸°ì¡´ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(existing_data)} í•­ëª©"
            if progress_callback:
                progress_callback(msg)
            print(msg)
            
            # 2. OpenAIë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ ë¶„ì„
            if progress_callback:
                progress_callback("ğŸ¤– OpenAI ë¶„ì„ ì‹œì‘...")
            print("ğŸ¤– OpenAI ë¶„ì„ ì‹œì‘...")
            if progress_callback:
                progress_callback("ğŸ¤– OpenAI API í˜¸ì¶œ ì¤‘...")
            content_analysis = self._analyze_with_openai(file_content, existing_data)
            if progress_callback:
                progress_callback("âœ… OpenAI ì‘ë‹µ ìˆ˜ì‹ ")
            msg = f"ğŸ“‹ íŒŒì‹±ëœ ê²°ê³¼: {len(content_analysis)} í•­ëª©"
            if progress_callback:
                progress_callback(msg)
            print("âœ… ë‚´ìš© ë¶„ì„ ì™„ë£Œ: {} í•­ëª©".format(len(content_analysis)))
            if progress_callback:
                progress_callback(f"âœ… ë‚´ìš© ë¶„ì„ ì™„ë£Œ: {len(content_analysis)} í•­ëª©")
            
            # 3. ì¶©ëŒ ë¶„ì„
            if progress_callback:
                progress_callback("âš ï¸ ì¶©ëŒ ë¶„ì„ ì‹œì‘...")
            print("âš ï¸ ì¶©ëŒ ë¶„ì„ ì‹œì‘...")
            if progress_callback:
                progress_callback("ğŸ¤– ì¶©ëŒ ë¶„ì„ OpenAI API í˜¸ì¶œ ì¤‘...")
            conflicts = self._analyze_conflicts_with_openai(content_analysis, existing_data)
            if progress_callback:
                progress_callback("âœ… ì¶©ëŒ ë¶„ì„ OpenAI ì‘ë‹µ ìˆ˜ì‹ ")
            msg = f"ğŸ“‹ ì¶©ëŒ ë¶„ì„ ê²°ê³¼: {len(conflicts)} í•­ëª©"
            if progress_callback:
                progress_callback(msg)
            print(f"âœ… ì¶©ëŒ ë¶„ì„ ì™„ë£Œ: {sum(len(v) for v in conflicts.values())}ê°œ ì¶©ëŒ")
            if progress_callback:
                progress_callback(f"âœ… ì¶©ëŒ ë¶„ì„ ì™„ë£Œ: {sum(len(v) for v in conflicts.values())}ê°œ ì¶©ëŒ")
            
            # 4. ì¶”ì²œ ìƒì„±
            if progress_callback:
                progress_callback("ğŸ’¡ ì¶”ì²œ ìƒì„± ì‹œì‘...")
            print("ğŸ’¡ ì¶”ì²œ ìƒì„± ì‹œì‘...")
            if progress_callback:
                progress_callback("ğŸ¤– ì¶”ì²œ ìƒì„± OpenAI API í˜¸ì¶œ ì¤‘...")
            recommendations = self._generate_recommendations_with_openai(content_analysis, existing_data, novel_name)
            if progress_callback:
                progress_callback("âœ… ì¶”ì²œ ìƒì„± OpenAI ì‘ë‹µ ìˆ˜ì‹ ")
            msg = f"ğŸ“‹ ì¶”ì²œ ìƒì„± ê²°ê³¼: {len(recommendations)} í•­ëª©"
            if progress_callback:
                progress_callback(msg)
            print(f"âœ… ì¶”ì²œ ìƒì„± ì™„ë£Œ: {sum(len(v) for v in recommendations.values())}ê°œ ì¶”ì²œ")
            if progress_callback:
                progress_callback(f"âœ… ì¶”ì²œ ìƒì„± ì™„ë£Œ: {sum(len(v) for v in recommendations.values())}ê°œ ì¶”ì²œ")
            
            # 5. ë¶„ì„ ê²°ê³¼ ì¢…í•©
            if progress_callback:
                progress_callback("ğŸ“‹ ê²°ê³¼ ì¢…í•© ì¤‘...")
            print("ğŸ“‹ ê²°ê³¼ ì¢…í•© ì¤‘...")
            analysis_result = {
                "file_name": file_name,
                "novel_name": novel_name,
                "content_analysis": content_analysis,
                "conflicts": conflicts,
                "recommendations": recommendations,
                "summary": self._generate_summary_with_openai(content_analysis, conflicts, recommendations)
            }
            if progress_callback:
                progress_callback("ğŸ¤– ìš”ì•½ ìƒì„± OpenAI API í˜¸ì¶œ ì¤‘...")
            if progress_callback:
                progress_callback("âœ… ìš”ì•½ ìƒì„± OpenAI ì‘ë‹µ ìˆ˜ì‹ ")
            print("ğŸ‰ ë¶„ì„ ì™„ë£Œ!")
            if progress_callback:
                progress_callback("ğŸ‰ ë¶„ì„ ì™„ë£Œ!")
            return analysis_result
            
        except Exception as e:
            msg = f"âŒ ë¶„ì„ ì˜¤ë¥˜: {e}"
            if progress_callback:
                progress_callback(msg)
            print(msg)
            return {
                "error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "file_name": file_name,
                "novel_name": novel_name
            }
    
    def _collect_existing_data(self, novel_name: str) -> Dict[str, Any]:
        """ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ìˆ˜ì§‘"""
        return {
            "characters": self.db_manager.get_characters(novel_name),
            "world_settings": self.db_manager.get_world_settings(novel_name),
            "timeline_events": self.db_manager.get_timeline_events(novel_name),
            "storyboards": self.db_manager.get_storyboards(novel_name)
        }
    
    def _analyze_with_openai(self, content: str, existing_data: Dict[str, Any]) -> Dict[str, Any]:
        """OpenAIë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ ë‚´ìš© ë¶„ì„"""
        
        system_prompt = """
        ë‹¹ì‹ ì€ ì†Œì„¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ ìµœëŒ€í•œ ìì„¸íˆ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

1. ë“±ì¥ì¸ë¬¼: ì´ë¦„, ì—­í• , ì„±ê²©, ì™¸ëª¨, ë§íˆ¬, ê°€ì¹˜ê´€, ê´€ê³„, ì„±ì¥ë°°ê²½, íŠ¸ë¼ìš°ë§ˆ, ì„¸ë¶€ íŠ¹ì„± ë“±
2. ì„¸ê³„ê´€ ìš”ì†Œ: ë§ˆë²•, ê¸°ìˆ , ì‚¬íšŒ êµ¬ì¡°, ë¬¸í™”, ê·œì¹™, ì—­ì‚¬, ìƒì§•, ê¸ˆê¸°, ì‹ í™”, ì •ì¹˜, ê²½ì œ, í™˜ê²½ ë“± ëª¨ë“  ì„¸ë¶€ í•­ëª©
3. ì£¼ìš” ì´ë²¤íŠ¸ (ì‹œê°„, ì¥ì†Œ, ì°¸ì—¬ì, ì¤‘ìš”ë„)
4. ì¥ì†Œ ì •ë³´
5. ì£¼ìš” í…Œë§ˆì™€ ì£¼ì œ
6. ìŠ¤í† ë¦¬ êµ¬ì¡° ë¶„ì„

ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""

        user_prompt = f"""ë‹¤ìŒ ì†Œì„¤ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

{content}

ê¸°ì¡´ ì„¤ì • ì •ë³´:
- ê¸°ì¡´ ì¸ë¬¼: {json.dumps([char.get('name', '') for char in existing_data['characters']], ensure_ascii=False)}
- ê¸°ì¡´ ì„¸ê³„ê´€: {json.dumps([world.get('name', '') for world in existing_data['world_settings']], ensure_ascii=False)}
- ê¸°ì¡´ ì´ë²¤íŠ¸: {json.dumps([event.get('title', '') for event in existing_data['timeline_events']], ensure_ascii=False)}

ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
{{
    "characters": [
        {{"name": "ì¸ë¬¼ëª…", "role": "ì—­í• ", "personality": "ì„±ê²©", "background": "ë°°ê²½"}}
    ],
    "world_elements": [
        {{"name": "ìš”ì†Œëª…", "category": "ë¶„ë¥˜", "description": "ì„¤ëª…"}}
    ],
    "events": [
        {{"date": "ë‚ ì§œ", "title": "ì œëª©", "description": "ì„¤ëª…", "importance": "ì¤‘ìš”ë„", "participants": ["ì°¸ì—¬ì"]}}
    ],
    "locations": ["ì¥ì†Œ1", "ì¥ì†Œ2"],
    "themes": ["í…Œë§ˆ1", "í…Œë§ˆ2"],
    "story_structure": {{"conflict": "ê°ˆë“±", "resolution": "í•´ê²°", "pacing": "ì „ê°œì†ë„"}}
}}
ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""

        system_prompt = system_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        user_prompt = user_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        try:
            print("ğŸ¤– OpenAI API í˜¸ì¶œ ì¤‘...")
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            print("âœ… OpenAI ì‘ë‹µ ìˆ˜ì‹ ")
            content = response.choices[0].message.content.strip()
            # ì½”ë“œë¸”ë¡ ì œê±°
            if content.startswith('```json'):
                content = content[7:]
            if content.startswith('```'):
                content = content[3:]
            if content.endswith('```'):
                content = content[:-3]
            content = content.strip()
            if not content:
                print("âŒ OpenAI ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
                raise ValueError("OpenAI ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            try:
                result = json.loads(content)
            except Exception as e:
                print("âŒ OpenAI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨:", content)
                raise ValueError(f"OpenAI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}\nì‘ë‹µ ë‚´ìš©: {content}")
            print(f"ğŸ“‹ íŒŒì‹±ëœ ê²°ê³¼: {len(result)} í•­ëª©")
            return result
            
        except Exception as e:
            print(f"âŒ OpenAI ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise
    
    def _analyze_conflicts_with_openai(self, content_analysis: Dict[str, Any], existing_data: Dict[str, Any]) -> Dict[str, Any]:
        """OpenAIë¥¼ ì‚¬ìš©í•œ ëª¨ìˆœ(contradiction) ë¶„ì„"""
        
        system_prompt = """
ë‹¹ì‹ ì€ ì†Œì„¤ ë‚´ìš©ì˜ ëª¨ìˆœ(contradiction)ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ë‘ ê°€ì§€ ìœ í˜•ì˜ ëª¨ìˆœì„ ì°¾ì•„ì£¼ì„¸ìš”:

1. ë‚´ë¶€ ëª¨ìˆœ: ì œê³µëœ ì†Œì„¤ ë‚´ìš© ë‚´ì—ì„œ ì„œë¡œ ëª¨ìˆœë˜ëŠ” ë¶€ë¶„
2. ì™¸ë¶€ ëª¨ìˆœ: ìƒˆë¡œìš´ ë‚´ìš©ê³¼ ê¸°ì¡´ ì„¤ì • ê°„ì˜ ë…¼ë¦¬ì  ëª¨ìˆœ

â€» ë‹¨, ê¸°ì¡´ DB(ì„¤ì •/ì¸ë¬¼/ì´ë²¤íŠ¸ ë“±)ì— ì—†ëŠ” ìƒˆë¡œìš´ ì •ë³´(ì‹ ê·œ ì¸ë¬¼, ì‹ ê·œ ì„¤ì •, ì‹ ê·œ ì´ë²¤íŠ¸ ë“±)ëŠ” ëª¨ìˆœì´ ì•„ë‹™ë‹ˆë‹¤. ë…¼ë¦¬ì ìœ¼ë¡œ ê¸°ì¡´ ì •ë³´ì™€ ì¶©ëŒ(ëª¨ìˆœ)ë˜ëŠ” ê²½ìš°ë§Œ ëª¨ìˆœìœ¼ë¡œ ê°„ì£¼í•˜ì„¸ìš”.

ê° ëª¨ìˆœì˜ ì‹¬ê°ë„ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”:
- ì‹¬ê°(ğŸ”´): ìŠ¤í† ë¦¬ ì „ì²´ì— ì˜í–¥ì„ ì£¼ëŠ” í•µì‹¬ ëª¨ìˆœ
- ë³´í†µ(ğŸŸ¡): ì¼ë¶€ ì„¤ì •ì´ë‚˜ ì„¸ë¶€ì‚¬í•­ì˜ ëª¨ìˆœ  
- ê²½ë¯¸(ğŸŸ¢): í‘œí˜„ì´ë‚˜ ì„¤ëª…ì˜ ì‘ì€ ë¶ˆì¼ì¹˜
"""

        user_prompt = f"""ë‹¤ìŒ ë‚´ìš©ì—ì„œ ëª¨ìˆœì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

ìƒˆë¡œìš´ ë‚´ìš©:
{json.dumps(content_analysis, ensure_ascii=False, indent=2)}

ê¸°ì¡´ ì„¤ì •:
{json.dumps(existing_data, ensure_ascii=False, indent=2)}

ëª¨ìˆœ ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
{{
    "internal_contradictions": [
        {{
            "type": "ë‚´ë¶€ ëª¨ìˆœ ìœ í˜• (ì¸ë¬¼/ì´ë²¤íŠ¸/ì„¸ê³„ê´€)",
            "description": "ëª¨ìˆœ ë‚´ìš© ì„¤ëª…",
            "severity": "ì‹¬ê°/ë³´í†µ/ê²½ë¯¸",
            "elements": ["ëª¨ìˆœë˜ëŠ” ìš”ì†Œ1", "ëª¨ìˆœë˜ëŠ” ìš”ì†Œ2"],
            "suggestion": "í•´ê²° ë°©ì•ˆ"
        }}
    ],
    "external_contradictions": [
        {{
            "type": "ì™¸ë¶€ ëª¨ìˆœ ìœ í˜• (ì¸ë¬¼/ì´ë²¤íŠ¸/ì„¸ê³„ê´€)",
            "description": "ëª¨ìˆœ ë‚´ìš© ì„¤ëª…", 
            "severity": "ì‹¬ê°/ë³´í†µ/ê²½ë¯¸",
            "new_element": "ìƒˆë¡œìš´ ë‚´ìš©",
            "existing_element": "ê¸°ì¡´ ì„¤ì •",
            "suggestion": "í•´ê²° ë°©ì•ˆ"
        }}
    ]
}}
ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""

        system_prompt = system_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        user_prompt = user_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        try:
            print("ğŸ¤– ëª¨ìˆœ ë¶„ì„ OpenAI API í˜¸ì¶œ ì¤‘...")
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.2,
                max_tokens=2000
            )
            
            print("âœ… ëª¨ìˆœ ë¶„ì„ OpenAI ì‘ë‹µ ìˆ˜ì‹ ")
            result = json.loads(response.choices[0].message.content)
            print(f"ğŸ“‹ ëª¨ìˆœ ë¶„ì„ ê²°ê³¼: {len(result.get('internal_contradictions', [])) + len(result.get('external_contradictions', []))}ê°œ ëª¨ìˆœ")
            return result
            
        except Exception as e:
            print(f"âŒ ëª¨ìˆœ ë¶„ì„ OpenAI ì‹¤íŒ¨: {e}")
            raise e
    
    def _generate_recommendations_with_openai(self, content_analysis: Dict[str, Any], existing_data: Dict[str, Any], novel_name: str) -> Dict[str, Any]:
        """OpenAIë¥¼ ì‚¬ìš©í•œ ì¶”ì²œ ìƒì„±"""
        
        system_prompt = """ë‹¹ì‹ ì€ ì†Œì„¤ ì°½ì‘ ì¡°ì–¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìŠ¤í† ë¦¬ ë°œì „ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ì¶”ì²œì„ ì œê³µí•´ì£¼ì„¸ìš”."""

        user_prompt = f"""ë‹¤ìŒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì†Œì„¤ ë°œì „ì„ ìœ„í•œ ì¶”ì²œì„ ìƒì„±í•´ì£¼ì„¸ìš”:

ìƒˆë¡œìš´ ë‚´ìš©:
{json.dumps(content_analysis, ensure_ascii=False, indent=2)}

ê¸°ì¡´ ì„¤ì •:
{json.dumps(existing_data, ensure_ascii=False, indent=2)}

ì†Œì„¤ëª…: {novel_name}

ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë³„ë¡œ êµ¬ì²´ì ì¸ ì¶”ì²œì„ ì œê³µí•´ì£¼ì„¸ìš”:
1. ìŠ¤í† ë¦¬ë³´ë“œ ë°œì „ ë°©í–¥
2. ì¸ë¬¼ ì„¤ì • ë³´ì™„ ì‚¬í•­
3. ì„¸ê³„ê´€ ì„¤ì • í™•ì¥
4. íƒ€ì„ë¼ì¸ êµ¬ì„± ê°œì„ 

JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
{{
    "storyboard_suggestions": ["ì¶”ì²œ1", "ì¶”ì²œ2"],
    "character_suggestions": ["ì¶”ì²œ1", "ì¶”ì²œ2"],
    "world_setting_suggestions": ["ì¶”ì²œ1", "ì¶”ì²œ2"],
    "timeline_suggestions": ["ì¶”ì²œ1", "ì¶”ì²œ2"]
}}
ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""

        system_prompt = system_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        user_prompt = user_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        try:
            print("ğŸ¤– ì¶”ì²œ ìƒì„± OpenAI API í˜¸ì¶œ ì¤‘...")
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=1500
            )
            
            print("âœ… ì¶”ì²œ ìƒì„± OpenAI ì‘ë‹µ ìˆ˜ì‹ ")
            result = json.loads(response.choices[0].message.content)
            print(f"ğŸ“‹ ì¶”ì²œ ìƒì„± ê²°ê³¼: {len(result)} í•­ëª©")
            return result
            
        except Exception as e:
            print(f"âŒ ì¶”ì²œ ìƒì„± OpenAI ì‹¤íŒ¨: {e}")
            raise e  # ì˜ˆì™¸ë¥¼ ê·¸ëŒ€ë¡œ ë°œìƒì‹œí‚´
    
    def _generate_summary_with_openai(self, content_analysis: Dict[str, Any], conflicts: Dict[str, Any], recommendations: Dict[str, Any]) -> str:
        """OpenAIë¥¼ ì‚¬ìš©í•œ ìš”ì•½ ìƒì„±"""
        
        system_prompt = """ë‹¹ì‹ ì€ ì†Œì„¤ ë¶„ì„ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼ë¥¼ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”."""

        user_prompt = f"""ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:

ë‚´ìš© ë¶„ì„:
{json.dumps(content_analysis, ensure_ascii=False, indent=2)}

ì¶©ëŒ ì •ë³´:
{json.dumps(conflicts, ensure_ascii=False, indent=2)}

ì¶”ì²œ ì‚¬í•­:
{json.dumps(recommendations, ensure_ascii=False, indent=2)}

í•œ ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ì„ ìš”ì•½í•´ì£¼ì„¸ìš”."""

        system_prompt = system_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        user_prompt = user_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        try:
            print("ğŸ¤– ìš”ì•½ ìƒì„± OpenAI API í˜¸ì¶œ ì¤‘...")
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=200
            )
            
            print("âœ… ìš”ì•½ ìƒì„± OpenAI ì‘ë‹µ ìˆ˜ì‹ ")
            result = response.choices[0].message.content.strip()
            print(f"ğŸ“‹ ìš”ì•½ ê²°ê³¼: {result}")
            return result
            
        except Exception as e:
            print(f"âŒ ìš”ì•½ ìƒì„± OpenAI ì‹¤íŒ¨: {e}")
            raise e  # ì˜ˆì™¸ë¥¼ ê·¸ëŒ€ë¡œ ë°œìƒì‹œí‚´
    
    def get_analysis_report(self, analysis_result: Dict[str, Any]) -> str:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜
        
        Args:
            analysis_result: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            í¬ë§·ëœ ë¶„ì„ ë¦¬í¬íŠ¸ ë¬¸ìì—´
        """
        if "error" in analysis_result:
            return f"âŒ ì˜¤ë¥˜: {analysis_result['error']}"
        
        report_parts = []
        
        # í—¤ë”
        report_parts.append(f"# ğŸ“Š AI ë¶„ì„ ê²°ê³¼: {analysis_result['file_name']}")
        report_parts.append("")
        
        # ìš”ì•½
        report_parts.append(f"## ğŸ“‹ ìš”ì•½")
        report_parts.append(analysis_result['summary'])
        report_parts.append("")
        
        # ìƒì„¸ ë¶„ì„
        content_analysis = analysis_result.get('content_analysis', {})
        
        if content_analysis.get('characters'):
            report_parts.append("## ğŸ‘¥ ë“±ì¥ì¸ë¬¼ ë¶„ì„")
            for char in content_analysis['characters']:
                report_parts.append(f"### {char.get('name', 'Unknown')}")
                report_parts.append(f"- **ì—­í• **: {char.get('role', 'ë¯¸ì •')}")
                report_parts.append(f"- **ì„±ê²©**: {char.get('personality', 'ë¯¸ì •')}")
                report_parts.append(f"- **ë°°ê²½**: {char.get('background', 'ë¯¸ì •')}")
                report_parts.append("")
        
        if content_analysis.get('world_elements'):
            report_parts.append("## ğŸŒ ì„¸ê³„ê´€ ìš”ì†Œ")
            for element in content_analysis['world_elements']:
                report_parts.append(f"### {element.get('name', 'Unknown')}")
                report_parts.append(f"- **ë¶„ë¥˜**: {element.get('category', 'ê¸°íƒ€')}")
                report_parts.append(f"- **ì„¤ëª…**: {element.get('description', '')}")
                report_parts.append("")
        
        if content_analysis.get('events'):
            report_parts.append("## ğŸ“… ì£¼ìš” ì´ë²¤íŠ¸")
            for event in content_analysis['events']:
                report_parts.append(f"### {event.get('title', 'Unknown')}")
                report_parts.append(f"- **ë‚ ì§œ**: {event.get('date', 'ë¯¸ì •')}")
                report_parts.append(f"- **ì¤‘ìš”ë„**: {event.get('importance', 'ë³´í†µ')}")
                report_parts.append(f"- **ì„¤ëª…**: {event.get('description', '')}")
                report_parts.append("")
        
        # ì¶©ëŒ ì •ë³´
        conflicts = analysis_result.get('conflicts', {})
        if any(conflicts.values()):
            report_parts.append("## âš ï¸ ë°œê²¬ëœ ì¶©ëŒ")
            
            if conflicts.get('character_conflicts'):
                report_parts.append("### ì¸ë¬¼ ì¶©ëŒ")
                for conflict in conflicts['character_conflicts']:
                    report_parts.append(f"- **{conflict.get('new_character', 'Unknown')}** â†”ï¸ **{conflict.get('existing_character', 'Unknown')}**")
                    report_parts.append(f"  - {conflict.get('description', '')}")
                report_parts.append("")
            
            if conflicts.get('world_setting_conflicts'):
                report_parts.append("### ì„¸ê³„ê´€ ì„¤ì • ì¶©ëŒ")
                for conflict in conflicts['world_setting_conflicts']:
                    report_parts.append(f"- **{conflict.get('new_element', 'Unknown')}** â†”ï¸ **{conflict.get('existing_element', 'Unknown')}**")
                    report_parts.append(f"  - {conflict.get('description', '')}")
                report_parts.append("")
            
            if conflicts.get('timeline_conflicts'):
                report_parts.append("### íƒ€ì„ë¼ì¸ ì¶©ëŒ")
                for conflict in conflicts['timeline_conflicts']:
                    report_parts.append(f"- **{conflict.get('new_event', 'Unknown')}** â†”ï¸ **{conflict.get('existing_event', 'Unknown')}**")
                    report_parts.append(f"  - {conflict.get('description', '')}")
                report_parts.append("")
        else:
            report_parts.append("## âœ… ì¶©ëŒ ì—†ìŒ")
            report_parts.append("ìƒˆë¡œ ì¶”ê°€ëœ ë‚´ìš©ê³¼ ê¸°ì¡´ ì„¤ì • ê°„ ì¶©ëŒì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            report_parts.append("")
        
        # ì¶”ì²œ ì‚¬í•­
        recommendations = analysis_result.get('recommendations', {})
        if any(recommendations.values()):
            report_parts.append("## ğŸ’¡ AI ì¶”ì²œ ì‚¬í•­")
            
            if recommendations.get('storyboard_suggestions'):
                report_parts.append("### ğŸ“ ìŠ¤í† ë¦¬ë³´ë“œ ë°œì „ ë°©í–¥")
                for suggestion in recommendations['storyboard_suggestions']:
                    report_parts.append(f"- {suggestion}")
                report_parts.append("")
            
            if recommendations.get('character_suggestions'):
                report_parts.append("### ğŸ‘¤ ì¸ë¬¼ ì„¤ì • ë³´ì™„")
                for suggestion in recommendations['character_suggestions']:
                    report_parts.append(f"- {suggestion}")
                report_parts.append("")
            
            if recommendations.get('world_setting_suggestions'):
                report_parts.append("### ğŸŒ ì„¸ê³„ê´€ ì„¤ì • í™•ì¥")
                for suggestion in recommendations['world_setting_suggestions']:
                    report_parts.append(f"- {suggestion}")
                report_parts.append("")
            
            if recommendations.get('timeline_suggestions'):
                report_parts.append("### ğŸ“… íƒ€ì„ë¼ì¸ êµ¬ì„± ê°œì„ ")
                for suggestion in recommendations['timeline_suggestions']:
                    report_parts.append(f"- {suggestion}")
                report_parts.append("")
        
        return "\n".join(report_parts)
    
    def extract_recommendations_with_openai(self, analysis_result, db_data, character_format_example=None):
        """
        OpenAIë¥¼ í™œìš©í•´ ë¶„ì„ ê²°ê³¼ì™€ DB(ì¸ë¬¼/ìŠ¤í† ë¦¬ë³´ë“œ)ë¥¼ ë¹„êµí•˜ì—¬ ì¶”ì²œ í•­ëª©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        ì¸ë¬¼/ì”¬ ëª¨ë‘ 'add'ì™€ 'update'ë¡œ ë¶„ë¦¬í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        character_format_example: ì¸ë¬¼ í¬ë§· ì˜ˆì‹œ(dict ë˜ëŠ” str)
        """
        system_prompt = """
        ë‹¹ì‹ ì€ ì†Œì„¤ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ ë¶„ì„ ê²°ê³¼ì™€ ê¸°ì¡´ DB(ì¸ë¬¼/ìŠ¤í† ë¦¬ë³´ë“œ)ë¥¼ ë¹„êµí•˜ì—¬, ë‹¤ìŒì„ ì¶”ì¶œí•˜ì„¸ìš”:
        1. ì¸ë¬¼: ì œê³µëœ ì¸ë¬¼ í¬ë§·ì— ë§ì¶° ì‹ ê·œ/ìˆ˜ì •/ë³´ì™„ì´ í•„ìš”í•œ ì¸ë¬¼ ì¶”ì²œ í•­ëª©ì„ 'add'ì™€ 'update'ë¡œ ë¶„ë¦¬
        2. ì”¬: ì¶”ê°€/ìˆ˜ì •ì´ í•„ìš”í•œ ì”¬ ì •ë³´ë¥¼ json í˜•íƒœë¡œ 'add'ì™€ 'update'ë¡œ ë¶„ë¦¬
        ê° í•­ëª©ë³„ë¡œ type(add/update), name, reason, data(í¬ë§·ì— ë§ëŠ” ì •ë³´)ë¥¼ í¬í•¨í•˜ì„¸ìš”.
        ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ì•„ë˜ JSON ì˜ˆì‹œ í¬ë§·ì„ ë”°ë¥´ì„¸ìš”.
        """
        
        # ì¸ë¬¼ í¬ë§· ì˜ˆì‹œ
        if character_format_example is None:
            character_format_example = {
                "name": "í™ê¸¸ë™",
                "role": "ì£¼ì¸ê³µ",
                "personality": "ìš©ê°í•˜ê³  ì •ì˜ë¡œì›€",
                "background": "ì¡°ì„ ì‹œëŒ€ ì˜ì "
            }
        
        user_prompt = f"""
        [ì¸ë¬¼ í¬ë§· ì˜ˆì‹œ]
        {json.dumps(character_format_example, ensure_ascii=False, indent=2)}

        [ë¶„ì„ ê²°ê³¼]
        {json.dumps(analysis_result, ensure_ascii=False, indent=2)}

        [ê¸°ì¡´ DB]
        {json.dumps(db_data, ensure_ascii=False, indent=2)}

        [JSON ë°˜í™˜ ì˜ˆì‹œ]
        {{
            "character_recommendations": {{
                "add": [
                    {{"name": "í™ê¸¸ë™", "reason": "ì‹ ê·œ ì¸ë¬¼", "data": {json.dumps(character_format_example, ensure_ascii=False)}}}
                ],
                "update": [
                    {{"name": "ì„êº½ì •", "reason": "ì„±ê²© ì •ë³´ ëˆ„ë½", "data": {json.dumps(character_format_example, ensure_ascii=False)}}}
                ]
            }},
            "storyboard_recommendations": {{
                "add": [
                    {{"target": "scene", "name": "ì”¬4", "reason": "ìƒˆë¡œìš´ ì´ë²¤íŠ¸", "data": {{"title": "ì”¬4", "description": "..."}}}}
                ],
                "update": [
                    {{"target": "scene", "name": "ì”¬2", "reason": "ë‚´ìš© ë¶ˆì¼ì¹˜", "data": {{"title": "ì”¬2", "description": "..."}}}}
                ]
            }}
        }}
        """
        
        system_prompt = system_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        user_prompt = user_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.2,
                max_tokens=2000
            )
            result = json.loads(response.choices[0].message.content)
            # add/updateê°€ ì—†ì„ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ë³´ì •
            for key in ["character_recommendations", "storyboard_recommendations"]:
                if key not in result:
                    result[key] = {"add": [], "update": []}
                else:
                    if "add" not in result[key]:
                        result[key]["add"] = []
                    if "update" not in result[key]:
                        result[key]["update"] = []
            return result
        except Exception as e:
            print(f"âŒ ì •ë³´ ì¶”ì¶œ OpenAI ì‹¤íŒ¨: {e}")
            return {
                "character_recommendations": {"add": [], "update": []},
                "storyboard_recommendations": {"add": [], "update": []}
            }

    def extract_new_storyboard_with_openai(self, analysis_result, storyboard_db_example):
        """
        OpenAIë¥¼ í™œìš©í•´ ê¸°ì¡´ ìŠ¤í† ë¦¬ë³´ë“œ DBì™€ ë¶„ì„ ê²°ê³¼ë¥¼ ë¹„êµ,
        ì¶”ê°€í•´ì•¼ í•  ì”¬ì„ ê¸°ì¡´ DBì™€ ë™ì¼í•œ í¬ë§·ì˜ JSON ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ
        """
        system_prompt = """
        ë‹¹ì‹ ì€ ì†Œì„¤ ìŠ¤í† ë¦¬ë³´ë“œ ë°ì´í„° ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ ê¸°ì¡´ ìŠ¤í† ë¦¬ë³´ë“œì™€ ì†Œì„¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë¹„êµí•´,
        ê¸°ì¡´ DBì— ì—†ëŠ”, ì¶”ê°€í•´ì•¼ í•  ì”¬ë§Œ ê¸°ì¡´ DBì™€ ë™ì¼í•œ JSON í¬ë§·ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.
        ë°˜ë“œì‹œ JSON ë¦¬ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•˜ì„¸ìš”.
        """
        user_prompt = f"""
        [ê¸°ì¡´ ìŠ¤í† ë¦¬ë³´ë“œ ì˜ˆì‹œ]
        {json.dumps(storyboard_db_example, ensure_ascii=False, indent=2)}

        [ì†Œì„¤ ë¶„ì„ ê²°ê³¼]
        {json.dumps(analysis_result, ensure_ascii=False, indent=2)}

        [ì¶”ê°€í•  ì”¬ JSON ë¦¬ìŠ¤íŠ¸ ì˜ˆì‹œ]
        [
          {{
            "title": "ìƒˆë¡œìš´ ì”¬",
            "description": "..."
          }}
        ]
        """
        system_prompt = system_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        user_prompt = user_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.2,
                max_tokens=2000
            )
            result = json.loads(response.choices[0].message.content)
            # --- í›„ì²˜ë¦¬: nameâ†’title ë³´ì • ---
            for elem in result:
                if 'name' in elem and 'title' not in elem:
                    elem['title'] = elem['name']
                    del elem['name']
            return result
        except Exception as e:
            print(f"âŒ ìŠ¤í† ë¦¬ë³´ë“œ ì¶”ê°€ ì¶”ì¶œ OpenAI ì‹¤íŒ¨: {e}")
            return []

    def extract_new_characters_with_openai(self, analysis_result, character_db_example, character_format_example):
        """
        OpenAIë¥¼ í™œìš©í•´ ê¸°ì¡´ ì¸ë¬¼ DBì™€ ë¶„ì„ ê²°ê³¼ë¥¼ ë¹„êµ,
        ì¶”ê°€í•´ì•¼ í•  ì¸ë¬¼ì„ ì¸ë¬¼ í¬ë§·ì˜ JSON ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ
        """
        system_prompt = """
        ë‹¹ì‹ ì€ ì†Œì„¤ ì¸ë¬¼ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ ê¸°ì¡´ ì¸ë¬¼ DBì™€ ì†Œì„¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë¹„êµí•´,
        ê¸°ì¡´ DBì— ì—†ëŠ”, ì¶”ê°€í•´ì•¼ í•  ì¸ë¬¼ë§Œ ë°˜ë“œì‹œ ì•„ë˜ ì¸ë¬¼ í¬ë§·(character_format_example)ì— ë§ëŠ” JSONìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.
        ë°˜ë“œì‹œ JSON ë¦¬ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•˜ì„¸ìš”.
        
        ì£¼ì˜ì‚¬í•­:
        1. ì†Œì„¤ ë¶„ì„ ê²°ê³¼ì˜ characters ë°°ì—´ì— ìˆëŠ” ì¸ë¬¼ ì •ë³´ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì„¸ìš”.
        2. ì¸ë¬¼ì˜ ì´ë¦„ì´ ê¸°ì¡´ DBì— ì—†ë‹¤ë©´ ë¬´ì¡°ê±´ ì¶”ê°€í•˜ì„¸ìš”.
        3. ê° ì¸ë¬¼ì€ character_format_exampleì˜ ëª¨ë“  í•„ë“œë¥¼ í¬í•¨í•´ì•¼ í•˜ë©°, ì •ë³´ê°€ ì—†ëŠ” í•„ë“œëŠ” ë¹ˆ ë¬¸ìì—´("")ë¡œ ì„¤ì •í•˜ì„¸ìš”.
        4. ì¸ë¬¼ì˜ ì´ë¦„ì€ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
        5. ì§€ë‚˜ê°€ëŠ” ì¸ë¬¼ì´ë¼ë„ ëª¨ë‘ ì¶”ì¶œí•˜ì„¸ìš”.
        """
        user_prompt = f"""
        [ì¸ë¬¼ í¬ë§· ì˜ˆì‹œ]
        {json.dumps(character_format_example, ensure_ascii=False, indent=2)}

        [ê¸°ì¡´ ì¸ë¬¼ ë°ì´í„°]
        {json.dumps(character_db_example, ensure_ascii=False, indent=2)}

        [ì†Œì„¤ ë¶„ì„ ê²°ê³¼]
        {json.dumps(analysis_result.get('content_analysis', {}), ensure_ascii=False, indent=2)}

        [ì¶”ê°€í•  ì¸ë¬¼ JSON ë¦¬ìŠ¤íŠ¸ ì˜ˆì‹œ]
        [
          {json.dumps(character_format_example, ensure_ascii=False, indent=2)}
        ]
        """
        system_prompt = system_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        user_prompt = user_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.2,
                max_tokens=2000
            )
            result = json.loads(response.choices[0].message.content)
            filtered = []
            existing_names = {char.get('name', '') or char.get('ì´ë¦„', '') for char in character_db_example}
            
            for char in result:
                # ì´ë¦„ì´ ì—†ìœ¼ë©´ ì œì™¸
                name = char.get('name', '') or char.get('ì´ë¦„', '')
                if not name:
                    continue
                    
                # ì´ë¯¸ DBì— ìˆëŠ” ì´ë¦„ì´ë©´ ì œì™¸
                if name in existing_names:
                    continue
                    
                # character_format_exampleì˜ ëª¨ë“  í•„ë“œê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •
                for k in character_format_example.keys():
                    if k not in char:
                        char[k] = ""
                
                filtered.append(char)
            
            return filtered
        except Exception as e:
            print(f"âŒ ì¸ë¬¼ ì¶”ê°€ ì¶”ì¶œ OpenAI ì‹¤íŒ¨: {e}")
            return []

    def extract_new_world_elements_with_openai(self, analysis_result, world_db_example, category_list):
        """
        OpenAIë¥¼ í™œìš©í•´ ê¸°ì¡´ ì„¸ê³„ê´€ DBì™€ ë¶„ì„ ê²°ê³¼ë¥¼ ë¹„êµ,
        ì¶”ê°€í•´ì•¼ í•  ì„¸ê³„ê´€ ìš”ì†Œë¥¼ ê¸°ì¡´ DBì™€ ë™ì¼í•œ í¬ë§·ì˜ JSON ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ
        ê° ìš”ì†Œì˜ categoryëŠ” category_list ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©
        ì¸ë¬¼/ìºë¦­í„° ê´€ë ¨ í•­ëª©ì€ world_elementsì—ì„œ ì œì™¸
        ë°˜ë“œì‹œ title í•„ë“œë¥¼ í¬í•¨í•´ì•¼ í•˜ë©°, nameì´ ìˆìœ¼ë©´ titleë¡œ ë³µì‚¬
        """
        system_prompt = """
        ë‹¹ì‹ ì€ ì†Œì„¤ ì„¸ê³„ê´€ ë°ì´í„° ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬, ê° ì„¸ê³„ê´€ ìš”ì†Œì˜ categoryëŠ” ë°˜ë“œì‹œ ë¦¬ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
        ë‹¨, ì¸ë¬¼(ìºë¦­í„°) ê´€ë ¨ í•­ëª©ì€ ë°˜ë“œì‹œ ì œì™¸í•˜ì„¸ìš”.
        ê° ì„¸ê³„ê´€ ìš”ì†ŒëŠ” ë°˜ë“œì‹œ title(ì„¤ì •ëª…) í•„ë“œë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
        categoryê°€ ì—†ê±°ë‚˜ ë¦¬ìŠ¤íŠ¸ì— ì—†ìœ¼ë©´ 'ê¸°íƒ€'ë¡œ ì„¤ì •í•˜ì„¸ìš”.
        titleì´ ì—†ìœ¼ë©´ nameì„ titleë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
        """
        user_prompt = f"""
        [ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸]
        {json.dumps(category_list, ensure_ascii=False)}

        [ê¸°ì¡´ ì„¸ê³„ê´€ DB ì˜ˆì‹œ]
        {json.dumps(world_db_example, ensure_ascii=False, indent=2)}

        [ì†Œì„¤ ë¶„ì„ ê²°ê³¼]
        {json.dumps(analysis_result, ensure_ascii=False, indent=2)}

        [ì¶”ê°€í•  ì„¸ê³„ê´€ ìš”ì†Œ JSON ë¦¬ìŠ¤íŠ¸ ì˜ˆì‹œ]
        [
          {{
            "title": "ìƒˆë¡œìš´ ì„¸ê³„ê´€ ìš”ì†Œ",
            "category": "ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜",
            "description": "..."
          }}
        ]
        """
        system_prompt = system_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        user_prompt = user_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.2,
                max_tokens=2000
            )
            result = json.loads(response.choices[0].message.content)
            filtered = []
            for elem in result:
                # nameâ†’title ë³€í™˜ ë³´ê°•
                if 'title' not in elem and 'name' in elem:
                    elem['title'] = elem['name']
                # category ë³´ì •
                if 'category' not in elem or elem['category'] not in category_list:
                    elem['category'] = 'ê¸°íƒ€'
                # ì¸ë¬¼/ìºë¦­í„° ê´€ë ¨ ì¹´í…Œê³ ë¦¬ ì œì™¸
                cat = elem.get('category', '').lower()
                if cat in ['ì¸ë¬¼', 'ìºë¦­í„°', 'person', 'character']:
                    continue
                # titleì´ ì—†ê±°ë‚˜ ë¹ˆ ê°’ì´ë©´ ì œì™¸
                if not elem.get('title'):
                    continue
                filtered.append(elem)
            return filtered
        except Exception as e:
            print(f"âŒ ì„¸ê³„ê´€ ì¶”ê°€ ì¶”ì¶œ OpenAI ì‹¤íŒ¨: {e}")
            return []

    def extract_new_timeline_with_openai(self, analysis_result, timeline_db_example):
        """
        OpenAIë¥¼ í™œìš©í•´ ê¸°ì¡´ íƒ€ì„ë¼ì¸ DBì™€ ë¶„ì„ ê²°ê³¼ë¥¼ ë¹„êµ,
        ì¶”ê°€í•´ì•¼ í•  íƒ€ì„ë¼ì¸ ì´ë²¤íŠ¸ë¥¼ ê¸°ì¡´ DBì™€ ë™ì¼í•œ í¬ë§·ì˜ JSON ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ
        ê° ì´ë²¤íŠ¸ì— explicit_events(bool) í•„ë“œë¥¼ í¬í•¨
        """
        system_prompt = """
        ë‹¹ì‹ ì€ ì†Œì„¤ íƒ€ì„ë¼ì¸ ë°ì´í„° ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ ê¸°ì¡´ íƒ€ì„ë¼ì¸ DBì™€ ì†Œì„¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë¹„êµí•´,
        ê¸°ì¡´ DBì— ì—†ëŠ”, ì¶”ê°€í•´ì•¼ í•  íƒ€ì„ë¼ì¸ ì´ë²¤íŠ¸ë§Œ ê¸°ì¡´ DBì™€ ë™ì¼í•œ JSON í¬ë§·ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.
        ê° ì´ë²¤íŠ¸ì—ëŠ” ë°˜ë“œì‹œ explicit_events(boolean) í•„ë“œë¥¼ í¬í•¨í•˜ì„¸ìš”. (ëª…ì‹œì  ì´ë²¤íŠ¸ë©´ true, ì•”ë¬µì ì´ë©´ false)
        'ëª…ì‹œì 'ì˜ ê¸°ì¤€: ì´ë²¤íŠ¸ì— ì‹œê°„(ë‚ ì§œ ë“±)ì´ ëª…í™•íˆ ëª…ì‹œë˜ì–´ ìˆìœ¼ë©´ ëª…ì‹œì (true), ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì•”ë¬µì (false)ìœ¼ë¡œ ê°„ì£¼í•˜ì„¸ìš”.
        ë°˜ë“œì‹œ JSON ë¦¬ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•˜ì„¸ìš”.
        """
        user_prompt = f"""
        [ê¸°ì¡´ íƒ€ì„ë¼ì¸ DB ì˜ˆì‹œ]
        {json.dumps(timeline_db_example, ensure_ascii=False, indent=2)}

        [ì†Œì„¤ ë¶„ì„ ê²°ê³¼]
        {json.dumps(analysis_result, ensure_ascii=False, indent=2)}

        [ì¶”ê°€í•  íƒ€ì„ë¼ì¸ ì´ë²¤íŠ¸ JSON ë¦¬ìŠ¤íŠ¸ ì˜ˆì‹œ]
        [
          {{
            "title": "ìƒˆë¡œìš´ ì´ë²¤íŠ¸",
            "date": "...",
            "description": "...",
            "importance": "...",
            "explicit_events": true
          }}
        ]
        """
        system_prompt = system_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        user_prompt = user_prompt.strip() + "\në°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(\`\`\`) ì—†ì´, ì„¤ëª…, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.2,
                max_tokens=2000
            )
            result = json.loads(response.choices[0].message.content)
            # --- í›„ì²˜ë¦¬: nameâ†’title ë³´ì •, explicit_events ë³´ì • ---
            for elem in result:
                if 'name' in elem and 'title' not in elem:
                    elem['title'] = elem['name']
                    del elem['name']
                # explicit_eventsê°€ ì—†ìœ¼ë©´ Falseë¡œ ë³´ì •
                if 'explicit_events' not in elem:
                    elem['explicit_events'] = False
            return result
        except Exception as e:
            print(f"âŒ íƒ€ì„ë¼ì¸ ì¶”ê°€ ì¶”ì¶œ OpenAI ì‹¤íŒ¨: {e}")
            return []

class SomnniAI:
    """
    DB(ì¸ë¬¼, ì„¸ê³„ê´€, íƒ€ì„ë¼ì¸, ìŠ¤í† ë¦¬ë³´ë“œ ë“±) ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì—ì´ì „íŠ¸
    """
    def __init__(self, database_path="Database"):
        from .utils import DatabaseManager
        self.db = DatabaseManager(database_path)

    def answer_query(self, novel_name: str, query: str) -> str:
        """
        ìì—°ì–´ ì§ˆë¬¸(query)ì— ëŒ€í•´ DBì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•„ OpenAIë¡œ ë‹µë³€ ìƒì„±
        """
        # DBì—ì„œ ëª¨ë“  ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
        characters = self.db.get_characters(novel_name)
        world = self.db.get_world_settings(novel_name)
        timeline = self.db.get_timeline_events(novel_name)
        storyboards = self.db.get_storyboards(novel_name)
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ ê¸°ë°˜ ìš”ì•½(í–¥í›„ embedding ë“±ìœ¼ë¡œ ê°œì„  ê°€ëŠ¥)
        import re
        query_lc = query.lower()
        matched = []
        for char in characters:
            if any(re.search(re.escape(str(val)), query_lc, re.IGNORECASE) for val in char.values() if isinstance(val, str)):
                matched.append(f"[ì¸ë¬¼] {char.get('name','') or char.get('ì´ë¦„','')}: {char}")
        for w in world:
            if any(re.search(re.escape(str(val)), query_lc, re.IGNORECASE) for val in w.values() if isinstance(val, str)):
                matched.append(f"[ì„¸ê³„ê´€] {w.get('title','') or w.get('name','')}: {w}")
        for t in timeline:
            if any(re.search(re.escape(str(val)), query_lc, re.IGNORECASE) for val in t.values() if isinstance(val, str)):
                matched.append(f"[íƒ€ì„ë¼ì¸] {t.get('title','') or t.get('date','')}: {t}")
        for s in storyboards:
            if any(re.search(re.escape(str(val)), query_lc, re.IGNORECASE) for val in s.values() if isinstance(val, str)):
                matched.append(f"[ìŠ¤í† ë¦¬ë³´ë“œ] {s.get('title','')}: {s}")
        if not matched:
            matched.append("DBì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        # OpenAIì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = """
        ë‹¹ì‹ ì€ ì†Œì„¤ ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ AI ë¹„ì„œì…ë‹ˆë‹¤. ì•„ë˜ DB ìš”ì•½ê³¼ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì°¸ê³ í•˜ì—¬, ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”. DB ìš”ì•½ì— ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ì •ë³´ë§Œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ê³ , ë¶ˆí•„ìš”í•œ ì •ë³´ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
        """
        db_summary = "\n".join(matched)
        user_prompt = f"""
        [DB ìš”ì•½]\n{db_summary}\n\n[ì§ˆë¬¸]\n{query}\n\n[ë‹µë³€]"""
        try:
            from openai import OpenAI
            import os
            api_key = os.getenv("OPENAI_API_KEY")
            client = OpenAI(api_key=api_key) if api_key else self.client
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt.strip()},
                    {"role": "user", "content": user_prompt.strip()}
                ],
                temperature=0.3,
                max_tokens=800
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"âŒ SomnniAI OpenAI ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            # fallback: DB ìš”ì•½ë§Œ ë°˜í™˜
            return db_summary

__all__ = [
    'OpenAINovelAnalysisAgent',
    'SomnniAI',
]
